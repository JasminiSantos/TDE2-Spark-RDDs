{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasminiSantos/TDE2-Spark-RDDs/blob/main/TDE2_Spark_RDDs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzlotXbYnKVS",
        "outputId": "680b3b58-219b-4853-dc64-0d77bd550d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfzmKeNESjdB",
        "outputId": "2abd8aa5-534a-4b0a-a184-6e8a9ca47e3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-19 22:27:53--  https://jpbarddal.github.io/assets/data/bigdata/transactions_amostra.csv.zip\n",
            "Resolving jpbarddal.github.io (jpbarddal.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to jpbarddal.github.io (jpbarddal.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47513871 (45M) [application/zip]\n",
            "Saving to: ‘transactions_amostra.csv.zip.1’\n",
            "\n",
            "transactions_amostr 100%[===================>]  45.31M   292MB/s    in 0.2s    \n",
            "\n",
            "2023-05-19 22:27:53 (292 MB/s) - ‘transactions_amostra.csv.zip.1’ saved [47513871/47513871]\n",
            "\n",
            "Archive:  transactions_amostra.csv.zip\n",
            "replace transactions_amostra.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!wget https://jpbarddal.github.io/assets/data/bigdata/transactions_amostra.csv.zip\n",
        "!unzip transactions_amostra.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AZyTxglQnh9"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder\\\n",
        ".master('local[*]')\\\n",
        ".appName('tde2').getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "# Load the dataset from CSV file\n",
        "dataset = sc.textFile(\"transactions_amostra.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEL7p2csuHP8"
      },
      "outputs": [],
      "source": [
        "# Printing column names\n",
        "columns = dataset.take(1)[0].split(\";\")\n",
        "print(\"Columns of the dataset:\")\n",
        "for column in columns:\n",
        "    print(column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScqnY98AQ0Rp"
      },
      "outputs": [],
      "source": [
        "# Problem 1: The number of transactions involving Brazil\n",
        "\n",
        "# Filter transactions involving Brazil\n",
        "brazil_transactions = dataset.filter(lambda line: \"Brazil\" in line)\n",
        "\n",
        "# Convert to PairRDD with a constant key\n",
        "brazil_transactions_with_key = brazil_transactions.map(lambda line: (\"brazil\", 1))\n",
        "\n",
        "# Calculate the total number of transactions involving Brazil\n",
        "total_brazil_transactions = brazil_transactions_with_key.reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Retrieve the count\n",
        "count = total_brazil_transactions.collect()[0][1]\n",
        "\n",
        "print(\"Total transactions involving Brazil:\", count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKBmVH_AR5HP"
      },
      "outputs": [],
      "source": [
        "# Problem 2: The number of transactions per flow type and year\n",
        "transactions_per_flow_year = dataset.map(lambda line: ((line.split(\";\")[4], line.split(\";\")[1]), 1)) \\\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        "for flow_year, count in transactions_per_flow_year.collect():\n",
        "    print(\"Flow type and year:\", flow_year, count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVQzh5XsR_6v"
      },
      "outputs": [],
      "source": [
        " #Problem 3: The average of commodity values per year\n",
        "\n",
        "# Process the dataset\n",
        "commodity_values = dataset.map(lambda line: (line.split(\";\")[1], float(line.split(\";\")[5])))\n",
        "commodity_values_per_year = commodity_values.aggregateByKey((0.0, 0), lambda a, b: (a[0] + b, a[1] + 1),\n",
        "                                                           lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
        "average_values_per_year = commodity_values_per_year.mapValues(lambda v: v[0] / v[1])\n",
        "\n",
        "for year, average_value in average_values_per_year.collect():\n",
        "    print(\"Average commodity value for year\", year, \":\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3eankDASGu_"
      },
      "outputs": [],
      "source": [
        "# Problem 4: The average price of commodities per unit type, year, and category in the export flow in Brazil\n",
        "\n",
        "# Process the dataset\n",
        "export_flow_brazil = dataset.filter(lambda line: \"Brazil\" in line and line.split(\";\")[4] == \"Export\")\n",
        "commodity_price_per_unit_type = export_flow_brazil.map(lambda line: ((line.split(\";\")[7], line.split(\";\")[1], line.split(\";\")[8]), float(line.split(\";\")[5])))\n",
        "commodity_price_per_unit_type_category = commodity_price_per_unit_type.aggregateByKey((0.0, 0), \n",
        "                                                                                      lambda a, b: (a[0] + b, a[1] + 1), \n",
        "                                                                                      lambda a, b: (a[0] + b[0], a[1] + b[1]))\n",
        "average_price_per_unit_type_category = commodity_price_per_unit_type_category.mapValues(lambda v: v[0] / v[1])\n",
        "print(\"Average price of commodities per unit type, year, and category in the export flow in Brazil:\")\n",
        "\n",
        "# Collect the results and print each element\n",
        "result = average_price_per_unit_type_category.collect()\n",
        "for element in result:\n",
        "    print(element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh0KuUonzTPG"
      },
      "outputs": [],
      "source": [
        "# Problem 5: The maximum, minimum, and mean transaction price per unit type and year\n",
        "\n",
        "# Process the dataset\n",
        "transactions = dataset.map(lambda line: ((line.split(\";\")[7], line.split(\";\")[1]), float(line.split(\";\")[5])))\n",
        "\n",
        "# Calculate maximum, minimum, and mean transaction price per unit type and year\n",
        "price_stats_per_unit_year = transactions.aggregateByKey((float('-inf'), float('inf'), 0.0, 0), \n",
        "                                                        lambda a, b: (max(a[0], b), min(a[1], b), a[2] + b, a[3] + 1),\n",
        "                                                        lambda a, b: (max(a[0], b[0]), min(a[1], b[1]), a[2] + b[2], a[3] + b[3]))\n",
        "\n",
        "# Calculate mean transaction price\n",
        "mean_price_per_unit_year = price_stats_per_unit_year.mapValues(lambda v: v[2] / v[3])\n",
        "\n",
        "# Iterate over the results and print maximum, minimum, and mean transaction prices per unit type and year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1N_n1eFzYM1"
      },
      "outputs": [],
      "source": [
        "# Problem 6: The country with the largest average commodity price in the Export flow\n",
        "\n",
        "# Filter the dataset for export flow\n",
        "export_flow = dataset.filter(lambda line: line.split(\";\")[4] == \"Export\")\n",
        "\n",
        "# Map each line to key-value pairs of (country, price)\n",
        "country_price = export_flow.map(lambda line: (line.split(\";\")[0], float(line.split(\";\")[5])))\n",
        "\n",
        "# Calculate the sum and count of prices for each country\n",
        "country_sum_count = country_price.aggregateByKey(\n",
        "    (0.0, 0),\n",
        "    lambda acc, price: (acc[0] + price, acc[1] + 1),\n",
        "    lambda acc1, acc2: (acc1[0] + acc2[0], acc1[1] + acc2[1])\n",
        ")\n",
        "\n",
        "# Calculate the average price for each country\n",
        "country_average_price = country_sum_count.mapValues(lambda acc: acc[0] / acc[1])\n",
        "\n",
        "# Find the country with the largest average price\n",
        "largest_average_price_country = country_average_price.max(lambda x: x[1])\n",
        "\n",
        "# Print the result\n",
        "print(\"Country with the largest average commodity price in the Export flow:\", largest_average_price_country[0], largest_average_price_country[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68hBbFjzSKVQ"
      },
      "outputs": [],
      "source": [
        "# Problem 7: The most commercialized commodity (summing the quantities) in 2016, per flow type\n",
        "commodity_quantities_2016 = dataset.filter(lambda line: line.split(\";\")[1] == \"2016\") \\\n",
        "    .map(lambda line: ((line.split(\";\")[3], line.split(\";\")[4]), float(line.split(\";\")[8]))) \\\n",
        "    .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "most_commercialized_commodity = commodity_quantities_2016.max(key=lambda x: x[1])\n",
        "\n",
        "most_commercialized_commodity = commodity_quantities_2016.max(key=lambda x: x[1])\n",
        "print(\"Most commercialized commodity in 2016:\", most_commercialized_commodity[0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIZuYMQeA2ZQ6NjzRHFqWW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}